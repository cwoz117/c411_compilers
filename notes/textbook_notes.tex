\documentclass{report}
\usepackage[hidelinks]{hyperref}
\usepackage{amsthm}
\usepackage{listings}
\usepackage{tikz}

\theoremstyle{definition}
\newtheorem*{examp}{Ex}

\title{Compilers Textbook Notes}
\author{Chris Wozniak}

\begin{document}
\maketitle
\tableofcontents
\chapter{Introduction}
	Compilers are computer programs that translate one language into another. It takes source code as input, and produces
	an equivalent program written in a target language. Usually this source language is a higher level language (C, C++) and the 
	target language is object/machine code for the target machine.

	\section{Translation Process}
		Internally a compiler consists of a number of \textbf{phases} that perform distinct logical operations. We will treat these
		phases as separate individual pieces, and could be coded as separate operations however they are usually grouped together.

		\subsection{Lexical Analysis}
			This phase reads in the source program as a string of characters. It collects meaningful sequences of characters into 
			a list of tokens, which are like words of a natural language.
			\begin{examp}
				This Code contains 17 characters, but we can extrapolate 9 tokens which define the expression.
				\begin{lstlisting}[language=c]
	a[index] = c + 3;

	a 	Identifier
	[	Left bracket
	index 	Identifier
	]	Right bracket
	= 	Assignment
	c 	Identifier
	+ 	Operation
	3	Number
	;	Terminator
				\end{lstlisting}
			\end{examp}
\newpage
		\subsection{Grammatical Analysis (Parser)}
			The parser receives the list of tokens provided by the lexical analysis, and performs \textbf{syntax analysis}, which
			determines if the structure of the expression is valid. It is similar to grammatical analysis on a sentance of natural language.\\
			The Parser returns an \textbf{Abstract Syntax Tree (AST)} or parse tree based on a Context Free Grammar, and its
			production rules as they are applied to the list of tokens. 
		\subsection{Semantic Analysis}
		\subsection{Optimization}
		\subsection{Code Generation}
\chapter{Lexical Analysis}
	The first step in compiling, the lexical analysis takes as input a stream of characters (source file) and returns a list of tokens, which are 
	logical units within the source code. This can be automated easily with regular expressions for pattern matching.
	
	\section{Review}
		\subsection{Regular Expressions}
			Regular Expressions represent patterns of strings. A regular expression \textit{r} is completely defined by the set of 
			strings it matches. The set is called "The language generated by the regular expression" and is denoted $L(r)$.
			There are 3 basic rules to regular expressions:
			\begin{enumerate}
				\item \textbf{Alternate Choices} - is an option from a set of characters, delimited by a ``\textbar" character:
					$L(a|b) = L(a) \cup L(b) = \{a, b\}$
				\item \textbf{Concatenation} - has no specific character, but is denoted by characters placed right 
					next to one another: $\{a|b\}c = \{ac, bc\}$ (c is concatenated to a or b)
				\item \textbf{Closure} - means repitition. This includes the empty string, $\epsilon$  as you can replace the 
					individual character $0\dots n$ times. $a* = \{\epsilon, a, aa, aaa, \dots\}$
			\end{enumerate}
			Extensions for regular expressions have shown up over the years and have been accepted to make lives easier, they are
			described here:
			\begin{itemize}
				\item \textbf{One or more repitions} - denoted by a $+$, it is just like closure, but does not include $\epsilon$.
				\item \textbf{Any Character} - denoted by ``$.$" this shows that any character can be in this position. 
					$(a|b).*$ describes any possible string in the language so long as it starts with an $a$ or $b$. 
				\item \textbf{Reserved Words and Identifiers} - words which are simply replaced by the expression identifier as needed.
					Numbers can be defined by ranges delimited by [, and ] respectively.
					\begin{examp} 
						Common terms to be defined by a regular expression in ranges: \\
						keyword = IF \textbar WHILE \textbar DO \\
						letter = [a-zA-Z] \\
						digit = [0-9] \\
						variable = letter(letter \textbar digit)*
					\end{examp}
				\item \textbf{Not} - 
				\item \textbf{Optional Sub-expressions} - 
			\end{itemize}
		\subsection{Deterministic Finite Automata}
		\subsection{Nondeterministic Finite Automata}
	\section{Scanning Process}
		\subsection{Defining tokens}
			Define token classes: Keywords, Identifiers, String literals, comments, etc.. Tokens classes  
			also have data associated with them. Therefore each token must save the value its for.
\begin{lstlisting}[language=c]
typedef enum {
	IF, THEN, ELSE, PLUS, MINUS, NUM, ID	// and more ..
} Token_type;

typedef struct {
	Token_type token;
	union {
		char *string_val;
		int num_val;
	}attribute;
}
\end{lstlisting}		
		













\end{document}