\documentclass{report}
\usepackage[hidelinks]{hyperref}
\usepackage{amsthm}
\usepackage{listings}
\usepackage{tikz}

\theoremstyle{definition}
\newtheorem*{examp}{Ex}

\title{Compilers Textbook Notes}
\author{Chris Wozniak}

\begin{document}
\maketitle
\tableofcontents
\chapter{Lexical Analysis}
	The first step in compiling, the lexical analysis takes as input a stream of characters (source file) and returns a list of tokens, which are 
	logical units within the source code. This can be automated easily with regular expressions for pattern matching.
	
	\section{Regular Expressions}	
		Represent patterns of strings. A RegEx is completely defined by the set of strings it matches (The language
		generated by the RegEx, $L(r)$ The set of legal characters is called the \textbf{alphabet}. Say the language
		allowed is any character in the alphabet, then the expression $(a|b)c = \{ac, bc\}$ where $a$, and $c$ could be
		any letters $[a-z]$
		\subsection{Basic RegEx's}
			Basic regular expressions are single characters which represent variables which can contain any 
			character within the language $\Sigma$. There are two special situations for basic regular expressions:
			\begin{enumerate}
				\item \textbf{The Empty String} denoted by $(\epsilon)$, it represents a string which contains no characters.
					Seen in languages such as c as ``". $(a|\epsilon) = \{a, \epsilon\}$
				\item \textbf{The Empty Set} denoted by $(\emptyset)$, it represents a set containing no strings at all, not
					even the empty set.
			\end{enumerate}
\newpage
		\subsection{RegEx Operations}
			Regular expressions have 3 basic operations to express how a pattern within a string can be matched as 
			described below, It is important to note that the order of operations is Closure, Concatenation, and finally
			Choice having the lowest precidence.
			\begin{enumerate}
				\item \textbf{Choice ( $|$ )} is known as a union of two languages, or choosing between one of two
					regular operations. $(a|b) = L(a) \cup L(b) = \{a, b\}$
				\item \textbf{Concatenation} is shown by appending values next to each other within the expression.
					Thus $(a|b|c)d = \{ad, bd, cd\}$ where the $d$ is concatenated to each possible option.
				\item \textbf{Closure ( * )} means the repetition of an expression $0$ or more times:
					$a* = \{\epsilon, a, aa, aaa, \ldots\}$ (note the use of the empty string)
			\end{enumerate}
		\subsection{RegEx Extensions}
			Extensions added for convenience.
			\begin{enumerate}
				\item \textbf{Range of Characters} We can define a range of characters inbetween square brackets:
					[0-9] means all numbers from 0 to 9.
				\item \textbf{Regular Definitions} are used when we assign a long set of regular expressions to a name 
					for ease of use/repitition.
					\begin{lstlisting}
	digit	[0-9]
	natural	{digit}{digit}*
					\end{lstlisting}
				\item \textbf{One or more} Writing examples like 'natural' above can become tedius to remove the $\epsilon$
					so we included the $+$ character to mean "one or more" thereby removing the need for writing $\{digit\}$
					twice.
				\item \textbf{Any Character} Instead of writing many cases for each character in a long language (say, the 
					ASCII standard), we can instead just use the ``." metacharacter to denote "any character within the set"
					Note that in programs like Lex the ``." means any character \textbf{except} the newline character.
				\item \textbf{Not} excludes expressions within the square brackets, $[\wedge ab]$ meaning "not a" and "not b"
				\item \textbf{Optional Subexpressions (?)} appended to an expression will denote "0 or 1 of this expression"
\begin{lstlisting}
	natural	[0-9]+
	signed	(+|-)?{natural}
\end{lstlisting} 
				shows off that the +, or - characters in a number are optional, there will be 0 or 1 of them.
			\end{enumerate}
	\section{Common Programming Tokens}
		Programming Languages tend to fall into several habits. These limited categories are all prettymuch standard
		across many different languages.
		\subsection{Numbers}
			Can be sequences of digits, decimal numbers, or exponents. Common interpretations are:
\begin{lstlisting}
	nat	[0-9]+
	signed	(+|-)?{nat}
	number	{signed}("."nat)?("E"{signed})?
\end{lstlisting}
			Note how the ``." and ``E" are in quotes to differentiate that we want the actual decimal point and E instead
			of meta-characters ( ``." normally being ``any character in the language).
		\subsection{Reserved Words}
			Reserved Words are the simplest to write, we can simply include them all in a regular definition:
\begin{lstlisting}
	reserved	if|while|do|for|...
\end{lstlisting}
		\subsection{Identifiers}
			Typical rules for identifiers are that we must start with a letter, then we can have a closed set of numbers
			and characters.
\begin{lstlisting}
	letter		[a-zA-Z]
	digit		[0-9]
	identifier	{letter}({letter}|{digit})*
\end{lstlisting}
		\subsection{Comments}
			Comments are ignored by the compiler, so here we will omit them from our tokens. We generally have two
			types of comments:
			\begin{enumerate}
				\item \textbf{Inline} comments are the easier of the two, we simply denote the start, then continue over
					every character that is not a newline.
\begin{lstlisting}
	//.*
\end{lstlisting}
				\item \textbf{Block} Block comments are hard since regular expressions cannot count which makes
					nested comments much more difficult. These require a more powerful tool, or ad-hoc methods 
					which are often used instead. (see the use in Lex).
			\end{enumerate}
		\subsection{Whitespace, Ambiguity and the Look ahead problem}
			We often run into ambiguous problems: variable names starting with keywords, character pairs representing one token
			when their individual characters are also tokens themselves. $(<, <>)$ for example. As mentioned in block
			comments, RegEx's aren't strong enough to handle this alone, so we encorporate \textbf{disambiguation rules}
			to solve our problems.
			\begin{itemize}
				\item \textbf{Principle of Largest Substring}
					Whenever a statement is ambiguous to multiple rules, the longest string takes precedence.
				\item \textbf{Keyword Precedence}
					If a word could either be an identifier or a keyword, the keyword is chosen.
				\item \textbf{Order of Occurance}
					If a statement is bound to two expressions (in parser expressions like Lex) the first one encountered
					is taken.
			\end{itemize}
	\section{Generating a Scanner Automatically}
		flex (Fast Lex) takes as input a text file containing regular expressions, and their required actions to perform them. It 
		produces an output file in c defining a table-driven implementation of a DFA which acts on a character.
		\subsection{Lex Conventions}
			\begin{itemize}
				\item Quotes denotes the actual character instead of the meta-characters. The backslash will 
					work as well, but with only one character.
				\item Lex understands all RegEx operations: $(+ * ( ) | ? . \wedge)$
				\item Sets of characters are in square brackets.
				\item The ``." represents any character except for a newline.
				\item Meta-characters except backslashes lose their meta associations in square brackets.
				\item Names must be used in curly brackets if they are used in an expression.
			\end{itemize}
\newpage
		\subsection{Input File Format}
\begin{lstlisting}
	{definitions}
	%%
	{rules}
	%%
	{Auxillary Routines}
\end{lstlisting}
			\subsubsection{Definitions}
				Before the first \%\% pair there are two main sections:
				\begin{enumerate}
					\item Any c-code that must be inserted external to functions used in the other two sections.
					\item Regular Definitions
				\end{enumerate}
			\subsubsection{Rules}
				Sequence of RegEx, followed by c code to be executed when the expression is matched. These pairs 
				must be separated by whitespace.
			\subsubsection{Auxillary Functions}
				\begin{itemize}
					\item Contains c-code for functions called in the rules section.
					\item Can also contain the main program, if we want to compile the lex as a standalone program.
				\end{itemize}
			\subsubsection{Lex Internal structures}
				\begin{itemize}
					\item \textbf{lex.yy.c} Lex output file name.
					\item \textbf{yylex()} Lex scanning routine (to call itself)
					\item \textbf{yytext} String matched by the current regular expression.
					\item \textbf{yyin} Lex input file
					\item \textbf{yyout} Lex output file
					\item \textbf{input} Lex buffered input routine
					\item \textbf{ECHO} Lex default action (prints yytext to yyout)
				\end{itemize}
			\subsubsection{Command Line Sequence}
				Note that this requires the ``flex-static" package to be installed if you wish to use the function yywrap().
				You could also define your own yywrap() to cycle through multiple files, or include the ``\%option noyywrap"
				at the top of your lex file (removing the ``-lfl" tag in gcc). This should limit you to using only one 
				input file however.
\begin{lstlisting}
vim example.lex
gcc lex.yy.c -lfl
./a.out < some_source.c
\end{lstlisting}
\end{document}
